pip install pyperclip
rm /Users/robincrifo/Documents/test/src/llm_client.py && cat > /Users/robincrifo/Documents/test/src/llm_client.py << 'EOF'
"""Client pour analyser des QCM avec Groq API (gratuit)."""

import os
from typing import Optional
import requests


class LLMClient:
    """Client pour analyser des QCM via Groq API."""

    QCM_PROMPT = """Tu es un expert qui analyse des QCM.

Pour CHAQUE question dans le texte :
1. Identifie la question
2. Liste toutes les options
3. Donne la BONNE R√âPONSE avec la lettre
4. Explique BRI√àVEMENT pourquoi

Format :

‚ùì QUESTION 1: [texte de la question]

Options:
A) ...
B) ...
C) ...
D) ...

‚úÖ R√âPONSE: [lettre]
üí° EXPLICATION: [explication courte et claire]

---

[R√©p√®te pour chaque question]"""

    def __init__(self, api_key: Optional[str] = None):
        """Initialise le client Groq."""
        self.api_key = api_key or os.getenv("GROQ_API_KEY")
        self.base_url = "https://api.groq.com/openai/v1"
        self.model = "llama-3.3-70b-versatile"
        
        if not self.api_key:
            raise ValueError(
                "Cl√© API Groq manquante.\n"
                "Obtenez une cl√© GRATUITE sur: https://console.groq.com\n"
                "Puis ajoutez GROQ_API_KEY dans .env"
            )

    def analyze_qcm_text(self, text: str) -> Optional[str]:
        """Analyse un texte de QCM et donne les r√©ponses."""
        url = f"{self.base_url}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": self.QCM_PROMPT},
                {"role": "user", "content": f"Voici le QCM √† analyser:\n\n{text}"}
            ],
            "temperature": 0.3,
            "max_tokens": 2000
        }

        try:
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            data = response.json()
            return data["choices"][0]["message"]["content"]
        except Exception as e:
            print(f"‚ùå Erreur Groq: {e}")
            return None


def create_llm_client(api_key: Optional[str] = None) -> LLMClient:
    """Factory pour cr√©er le client."""
    return LLMClient(api_key=api_key)
EOF
osascript -e 'display notification "Test de notification" with title "Test" sound name "Glass"'
# Configuration LLM
# Option A: OpenAI API
OPENAI_API_KEY=your_openai_api_key_here
git init
LLM_MODEL=gpt-4o-mini

# Option B: Autre endpoint compatible OpenAI
# LLM_BASE_URL=https://api.custom-provider.com/v1
# LLM_API_KEY=your_api_key_here
cat > /Users/robincrifo/Documents/test/README.md << 'EOF'
# üéì QCM Screen Analyzer

Application Python pour capturer automatiquement des QCM √† l'√©cran, extraire le texte par OCR et obtenir les r√©ponses via IA.

## ‚ú® Fonctionnalit√©s

- **Capture d'√©cran automatique** : Appuyez sur `=` pour capturer
- **OCR en ligne** : Extraction de texte via OCRSpace API (gratuit)
- **Analyse IA** : R√©ponses aux QCM via Groq API (gratuit)
- **Popup de r√©sultats** : Affichage des r√©ponses dans une fen√™tre contextuelle
- **Aucune sauvegarde** : Pas de donn√©es √©crites sur le disque

## üìã Pr√©requis

- **Python 3.11+** (test√© sur Python 3.14)
- **macOS** (ou Windows/Linux avec adaptations)
- Compte gratuit [OCRSpace](https://ocr.space/ocrapi) pour l'OCR
- Compte gratuit [Groq](https://console.groq.com) pour l'IA

## üöÄ Installation

### 1. Cloner le projet

```bash
git clone https://github.com/VOTRE_USERNAME/qcm-screen-analyzer.git
cd qcm-screen-analyzer
```

### 2. Cr√©er un environnement virtuel

```bash
python3 -m venv venv
source venv/bin/activate  # Sur macOS/Linux
# venv\Scripts\activate   # Sur Windows
```

### 3. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

## ‚öôÔ∏è Configuration

### 1. Cr√©er le fichier `.env`

Copiez le fichier d'exemple :

```bash
cp .env.example .env
```

### 2. Obtenir les cl√©s API gratuites

#### **OCRSpace API** (pour l'OCR)
1. Allez sur https://ocr.space/ocrapi
2. Inscrivez-vous gratuitement
3. Copiez votre cl√© API
4. Quota gratuit : **25,000 requ√™tes/mois**

#### **Groq API** (pour l'IA)
1. Allez sur https://console.groq.com
2. Cr√©ez un compte
3. G√©n√©rez une cl√© API
4. Quota gratuit : **30 requ√™tes/minute**, **14,400/jour**

### 3. Configurer le fichier `.env`

Ouvrez le fichier `.env` et ajoutez vos cl√©s :

```bash
# Configuration OCRSpace API (obligatoire)
OCRSPACE_API_KEY=votre_cl√©_ocrspace_ici
OCR_LANGUAGE=fre

# Configuration Groq API (obligatoire pour l'analyse IA)
USE_LLM=true
GROQ_API_KEY=votre_cl√©_groq_ici

# Mode debug (optionnel)
DEBUG_MODE=false
DEBUG_SAVE_SCREENSHOTS=false
```

**Exemple de fichier `.env` configur√© :**

```bash
OCRSPACE_API_KEY=K87654321
OCR_LANGUAGE=fre
USE_LLM=true
GROQ_API_KEY=gsk_abc123xyz456
DEBUG_MODE=false
DEBUG_SAVE_SCREENSHOTS=false
```

### 4. V√©rifier la configuration

Assurez-vous que :
- ‚úÖ Le fichier `.env` existe dans le dossier racine
- ‚úÖ Les deux cl√©s API sont correctement copi√©es (sans espaces)
- ‚úÖ `USE_LLM=true` pour activer l'analyse IA
- ‚úÖ Le fichier `.env` n'est **PAS** committ√© sur Git (d√©j√† dans `.gitignore`)

## üéÆ Utilisation

### Lancer l'application

```bash
python main.py
```

Vous verrez :

```
üöÄ Screen Tutor Assistant d√©marr√©
   OCR: OCRSpace API (fre)
   LLM: ‚úì Activ√© (Groq API)
   Mode debug: ‚úó D√©sactiv√©

üìå Raccourcis:
   = - Capturer l'√©cran et analyser
   ESC - Quitter l'application

‚ú® Les r√©ponses s'afficheront en popup
En attente...
```

### Utiliser l'application

1. **Appuyez sur `=`** pour capturer l'√©cran complet
2. L'OCR extrait le texte du QCM
3. L'IA analyse et trouve les r√©ponses
4. Une **popup** s'affiche avec les r√©sultats
5. **Appuyez sur ESC** pour quitter

## üìÅ Structure du projet

```
qcm-screen-analyzer/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ capture.py       # Capture d'√©cran (mss)
‚îÇ   ‚îú‚îÄ‚îÄ ocr_api.py       # OCR via OCRSpace API
‚îÇ   ‚îî‚îÄ‚îÄ llm_client.py    # Client IA Groq
‚îú‚îÄ‚îÄ main.py              # Point d'entr√©e
‚îú‚îÄ‚îÄ requirements.txt     # D√©pendances
‚îú‚îÄ‚îÄ .env.example         # Template de configuration
‚îú‚îÄ‚îÄ .env                 # Votre configuration (NON commit√©)
‚îú‚îÄ‚îÄ .gitignore           # Fichiers ignor√©s par Git
‚îî‚îÄ‚îÄ README.md            # Ce fichier
```

## üîí S√©curit√©

- ‚úÖ Les cl√©s API sont dans `.env` (ignor√© par Git)
- ‚úÖ Aucune sauvegarde de captures d'√©cran par d√©faut
- ‚úÖ Pas de logs sensibles
- ‚úÖ Timeouts r√©seau configur√©s
- ‚ö†Ô∏è **Ne partagez JAMAIS votre fichier `.env`**

## üêõ D√©pannage

### "Cl√© API OCRSpace manquante"
‚û°Ô∏è V√©rifiez que `OCRSPACE_API_KEY` est dans `.env`

### "Groq API key manquante"
‚û°Ô∏è V√©rifiez que `GROQ_API_KEY` est dans `.env` et `USE_LLM=true`

### "Erreur OCRSpace: File size exceeds"
‚û°Ô∏è L'image est automatiquement compress√©e, v√©rifiez votre connexion

### Rate limit d√©pass√©
‚û°Ô∏è Groq gratuit : max 30 req/min. Attendez quelques secondes.

### Permissions macOS
‚û°Ô∏è Autorisez Terminal dans **Pr√©f√©rences Syst√®me > Confidentialit√© > Accessibilit√©**

## ÔøΩÔøΩ Limites gratuites

| Service | Limite gratuite |
|---------|----------------|
| **OCRSpace** | 25,000 requ√™tes/mois |
| **Groq** | 30 req/min, 14,400/jour |

## üìù License

MIT License - Libre d'utilisation

## ü§ù Contribution

Les contributions sont les bienvenues ! Ouvrez une issue ou un PR.

---

**Note** : Cette application est destin√©e √† un usage personnel √©ducatif. Respectez les conditions d'utilisation des API tierces.
EOF
# LLM_MODEL=custom-model-name

# Configuration OCR
TESSERACT_LANG=fra+eng
OCR_MIN_TEXT_LENGTH=30

# Configuration R√©seau
LLM_TIMEOUT=30
LLM_MAX_RETRIES=1

# Mode confidentialit√© (true/false)
PRIVACY_MODE=true

# Mode debug (true/false) - d√©sactiver en production
DEBUG_MODE=false
DEBUG_SAVE_SCREENSHOTS=false
