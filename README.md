# Screen Tutor Assistant ğŸ“

Application desktop Windows en Python pour analyser des captures d'Ã©cran de questions (QCM, exercices) via OCR local et obtenir des explications pÃ©dagogiques d'un LLM tuteur.

## ğŸ¯ FonctionnalitÃ©s

- **Capture d'Ã©cran instantanÃ©e** : Appuyez sur `P` pour capturer l'Ã©cran complet
- **OCR local** : Extraction de texte avec Tesseract (franÃ§ais + anglais)
- **Mode tuteur intelligent** : Explications et indices sans rÃ©vÃ©ler la rÃ©ponse immÃ©diatement
- **Interface overlay** : FenÃªtre toujours visible avec bouton "RÃ©vÃ©ler"
- **Mode confidentialitÃ©** : Masquage automatique des donnÃ©es personnelles (emails, tÃ©lÃ©phones, numÃ©ros)
- **SÃ©curitÃ©** : Pas de sauvegarde des captures (sauf mode debug), timeouts rÃ©seau, gestion d'erreurs

## ğŸ“‹ PrÃ©requis

### Python
- Python 3.11 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

### Tesseract OCR (Windows)

**Option 1 : Installation avec installeur**
1. TÃ©lÃ©chargez l'installeur depuis : https://github.com/UB-Mannheim/tesseract/wiki
2. Lancez l'installeur et suivez les instructions
3. **Important** : Cochez "Additional language data (download)" et sÃ©lectionnez `fra` (FranÃ§ais)
4. Par dÃ©faut, Tesseract s'installe dans `C:\Program Files\Tesseract-OCR`

**Option 2 : Via Chocolatey**
```powershell
choco install tesseract
```

**VÃ©rification de l'installation**
```powershell
tesseract --version
```

Si la commande n'est pas reconnue, ajoutez `C:\Program Files\Tesseract-OCR` au PATH systÃ¨me.

### ClÃ© API LLM
- ClÃ© API OpenAI (recommandÃ©) : https://platform.openai.com/api-keys
- OU tout autre endpoint compatible OpenAI

## ğŸš€ Installation

### 1. Cloner ou tÃ©lÃ©charger le projet
```bash
cd screen-tutor-assistant
```

### 2. CrÃ©er un environnement virtuel (recommandÃ©)
```powershell
# Windows PowerShell
python -m venv venv
.\venv\Scripts\Activate.ps1

# Windows CMD
python -m venv venv
venv\Scripts\activate.bat
```

### 3. Installer les dÃ©pendances Python
```bash
pip install -r requirements.txt
```

### 4. Configurer les variables d'environnement
```bash
# Copier le fichier exemple
cp .env.example .env
```

Ã‰ditez le fichier `.env` et configurez :
```env
# Configuration LLM
OPENAI_API_KEY=sk-votre-clÃ©-api-ici
LLM_MODEL=gpt-4o-mini

# Configuration OCR
TESSERACT_LANG=fra+eng
OCR_MIN_TEXT_LENGTH=30

# Configuration RÃ©seau
LLM_TIMEOUT=30
LLM_MAX_RETRIES=1

# Mode confidentialitÃ©
PRIVACY_MODE=true

# Mode debug (dÃ©sactiver en production)
DEBUG_MODE=false
DEBUG_SAVE_SCREENSHOTS=false
```

**Configuration avancÃ©e** (endpoint personnalisÃ©) :
```env
# Pour utiliser un autre fournisseur compatible OpenAI
LLM_BASE_URL=https://api.votre-fournisseur.com/v1
LLM_API_KEY=votre-clÃ©-api
LLM_MODEL=nom-du-modele
```

### 5. Configuration Tesseract (si nÃ©cessaire)

Si Tesseract n'est pas dans le PATH, vous pouvez spÃ©cifier le chemin dans le code.

Ã‰ditez `src/ocr.py` et ajoutez aprÃ¨s les imports :
```python
import pytesseract
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
```

## ğŸ“– Utilisation

### Lancer l'application
```bash
python main.py
```

Vous verrez :
```
ğŸš€ Screen Tutor Assistant dÃ©marrÃ©
   Mode confidentialitÃ©: âœ“ ActivÃ©
   Mode debug: âœ— DÃ©sactivÃ©

ğŸ“Œ Raccourcis:
   P - Capturer l'Ã©cran et analyser
   ESC - Quitter l'application

En attente...
```

### Workflow
1. **Affichez votre question** (QCM, exercice) sur l'Ã©cran
2. **Appuyez sur `P`** pour capturer
3. L'application :
   - ğŸ“¸ Capture l'Ã©cran
   - ğŸ” Extrait le texte via OCR
   - ğŸ”’ Masque les donnÃ©es sensibles (si mode confidentialitÃ© activÃ©)
   - ğŸ¤– Envoie au LLM pour obtenir une explication
4. Une **fenÃªtre overlay** apparaÃ®t avec :
   - Le texte OCR extrait
   - L'explication pÃ©dagogique + indice
   - Bouton "RÃ©vÃ©ler la rÃ©ponse"
5. **Cliquez sur "RÃ©vÃ©ler"** pour obtenir la rÃ©ponse finale avec justification
6. **Utilisez les boutons** :
   - ğŸ“‹ Copier : Copie le contenu dans le presse-papiers
   - âŒ Fermer : Ferme la fenÃªtre

### Raccourcis clavier
- **P** : Capturer et analyser l'Ã©cran
- **ESC** : Quitter l'application

## ğŸ”’ Mode ConfidentialitÃ©

Le mode confidentialitÃ© (activÃ© par dÃ©faut) dÃ©tecte et masque automatiquement :
- âœ‰ï¸ Emails
- ğŸ“± NumÃ©ros de tÃ©lÃ©phone (format franÃ§ais)
- ğŸ’³ NumÃ©ros longs (cartes bancaires, etc.)
- ğŸ†” NumÃ©ros de sÃ©curitÃ© sociale
- ğŸ¦ IBAN
- ğŸŒ Adresses IP

**DÃ©sactivation** : Mettez `PRIVACY_MODE=false` dans `.env`

## ğŸ› Mode Debug

Pour diagnostiquer des problÃ¨mes :

1. Activez le mode debug dans `.env` :
```env
DEBUG_MODE=true
DEBUG_SAVE_SCREENSHOTS=true
```

2. Les captures d'Ã©cran seront sauvegardÃ©es dans `debug_screenshots/`
3. Des messages dÃ©taillÃ©s seront affichÃ©s dans la console

**âš ï¸ N'oubliez pas de dÃ©sactiver en production !**

## ğŸ§ª Tests

ExÃ©cuter les tests unitaires :
```bash
# Tous les tests
pytest

# Avec verbositÃ©
pytest -v

# Un fichier spÃ©cifique
pytest tests/test_privacy.py

# Avec couverture
pytest --cov=src tests/
```

Tests disponibles :
- `test_ocr.py` : Preprocessing et extraction OCR
- `test_privacy.py` : DÃ©tection et masquage de donnÃ©es sensibles
- `test_llm_client.py` : Client HTTP avec mocks

## ğŸ“ Structure du Projet

```
screen-tutor-assistant/
â”œâ”€â”€ src/                      # Code source
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ capture.py           # Capture d'Ã©cran (mss)
â”‚   â”œâ”€â”€ ocr.py               # OCR avec preprocessing (pytesseract)
â”‚   â”œâ”€â”€ llm_client.py        # Client LLM (OpenAI compatible)
â”‚   â”œâ”€â”€ privacy.py           # Filtre de confidentialitÃ©
â”‚   â””â”€â”€ ui.py                # Interface overlay (tkinter)
â”œâ”€â”€ tests/                    # Tests unitaires
â”‚   â”œâ”€â”€ test_ocr.py
â”‚   â”œâ”€â”€ test_privacy.py
â”‚   â””â”€â”€ test_llm_client.py
â”œâ”€â”€ main.py                   # Point d'entrÃ©e
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”œâ”€â”€ .env.example             # Template configuration
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                # Cette documentation
```

## âš™ï¸ Configuration AvancÃ©e

### Personnaliser l'OCR
Dans `.env` :
```env
# Langues (sÃ©parÃ©es par +)
TESSERACT_LANG=fra+eng+deu

# Longueur minimale de texte
OCR_MIN_TEXT_LENGTH=50
```

### Personnaliser le LLM
```env
# Timeout (secondes)
LLM_TIMEOUT=60

# Nombre de tentatives
LLM_MAX_RETRIES=2

# ModÃ¨le
LLM_MODEL=gpt-4
```

### Modifier le prompt tuteur
Ã‰ditez `src/llm_client.py` et modifiez `TUTOR_SYSTEM_PROMPT`.

## ğŸ”§ DÃ©pannage

### Erreur "Tesseract not found"
- VÃ©rifiez que Tesseract est installÃ© : `tesseract --version`
- Ajoutez le chemin dans le PATH ou spÃ©cifiez-le dans `src/ocr.py`

### Erreur "API key manquante"
- VÃ©rifiez que le fichier `.env` existe
- VÃ©rifiez que `OPENAI_API_KEY` est dÃ©fini dans `.env`

### Texte OCR vide ou incomplet
- Augmentez la rÃ©solution de votre Ã©cran
- Zoomez sur le texte avant de capturer
- Assurez-vous que le texte est net et contrastÃ©
- VÃ©rifiez que les langues sont bien installÃ©es pour Tesseract

### Hotkey ne fonctionne pas
- ExÃ©cutez le script avec les privilÃ¨ges administrateur (certains hotkeys globaux le requiÃ¨rent)
- VÃ©rifiez qu'aucune autre application n'utilise la touche `P`

### Timeout LLM
- Augmentez `LLM_TIMEOUT` dans `.env`
- VÃ©rifiez votre connexion Internet
- VÃ©rifiez que votre clÃ© API est valide

## ğŸ“ Limitations

- **Windows uniquement** : L'application est optimisÃ©e pour Windows (keyboard, mss)
- **Tesseract requis** : OCR local nÃ©cessite une installation sÃ©parÃ©e de Tesseract
- **Hotkey global** : Peut nÃ©cessiter des privilÃ¨ges administrateur
- **PrÃ©cision OCR** : DÃ©pend de la qualitÃ© de la capture (rÃ©solution, contraste)

## ğŸ›¡ï¸ SÃ©curitÃ© & ConfidentialitÃ©

- âœ… Pas de sauvegarde des captures (sauf mode debug)
- âœ… Masquage automatique des donnÃ©es personnelles
- âœ… Variables d'environnement pour les clÃ©s API
- âœ… Timeouts rÃ©seau configurables
- âœ… Gestion des erreurs et exceptions
- âœ… Logs minimaux (pas de donnÃ©es sensibles loggÃ©es)

## ğŸ“œ Licence

Ce projet est fourni "tel quel" Ã  des fins Ã©ducatives.

## ğŸ¤ Contribution

Pour contribuer :
1. Forkez le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'Add AmazingFeature'`)
4. Pushez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

## ğŸ“ Support

En cas de problÃ¨me :
1. Consultez la section **DÃ©pannage** ci-dessus
2. Activez le mode debug pour plus d'informations
3. VÃ©rifiez que toutes les dÃ©pendances sont installÃ©es
4. Ouvrez une issue sur GitHub avec les logs

---

**DÃ©veloppÃ© avec â¤ï¸ pour faciliter l'apprentissage**
